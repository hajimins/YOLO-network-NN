{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c11c626-533c-48b7-8d25-c21df9cff78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8efa3be7-6a36-4816-ac8d-587c0eddbc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsfile = 'coco_data/yolov3.weights'\n",
    "classfile = 'coco_data/coco.names'\n",
    "cfgfile = 'coco_data/yolov3.cfg'\n",
    "sample_img1 = 'coco_data/input/img.jpg'\n",
    "input_dir = 'coco_data/input'\n",
    "output_dir = 'coco_data/output'\n",
    "nms_thesh = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a65fc6-ad0c-479e-8578-2d9871d03267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download yolov3.cfg\n",
    "url1 = 'https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg'\n",
    "response1 = requests.get(url1)\n",
    "with open('yolov3.cfg', 'wb') as file:\n",
    "    file.write(response1.content)\n",
    "\n",
    "# Download dog-cycle-car.png\n",
    "url2 = 'https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png'\n",
    "response2 = requests.get(url2)\n",
    "with open('dog-cycle-car.png', 'wb') as file:\n",
    "    file.write(response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff078c0-d070-49f0-8c9f-6c6b97d629f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(config_file):\n",
    "    file = open(config_file,'r')\n",
    "    file = file.read().split('\\n')\n",
    "    file =  [line for line in file if len(line)>0 and line[0] != '#']\n",
    "    file = [line.lstrip().rstrip() for line in file]\n",
    "\n",
    "    final_list = []\n",
    "    element_dict = {}\n",
    "    for line in file:\n",
    "\n",
    "        if line[0] == '[':\n",
    "            if len(element_dict) != 0:     # appending the dict stored on previous iteration\n",
    "                    final_list.append(element_dict)\n",
    "                    element_dict = {} # again emtying dict\n",
    "            element_dict['type'] = ''.join([i for i in line if i != '[' and i != ']'])\n",
    "            \n",
    "        else:\n",
    "            val = line.split('=')\n",
    "            element_dict[val[0].rstrip()] = val[1].lstrip()  #removing spaces on left and right side\n",
    "        \n",
    "    final_list.append(element_dict) # appending the values stored for last set\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae43d26-9e4c-4bc1-95ec-f4d9a7db4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DummyLayer, self).__init__()\n",
    "        \n",
    "\n",
    "        \n",
    "class DetectionLayer(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super(DetectionLayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "        \n",
    "        \n",
    "\n",
    "def create_model(blocks):\n",
    "#     blocks = parse_cfg(cfgfile)\n",
    "    darknet_details = blocks[0]\n",
    "    channels = 3 \n",
    "    output_filters = []\n",
    "    modulelist = nn.ModuleList()\n",
    "    \n",
    "    for i,block in enumerate(blocks[1:]):\n",
    "        seq = nn.Sequential()\n",
    "        if (block[\"type\"] == \"convolutional\"):\n",
    "            activation = block[\"activation\"]\n",
    "            filters = int(block[\"filters\"])\n",
    "            kernel_size = int(block[\"size\"])\n",
    "            strides = int(block[\"stride\"])\n",
    "            use_bias= False if (\"batch_normalize\" in block) else True\n",
    "            pad = (kernel_size - 1) // 2\n",
    "            \n",
    "            conv = nn.Conv2d(in_channels=channels, out_channels=filters, kernel_size=kernel_size, \n",
    "                             stride=strides, padding=pad, bias = use_bias)\n",
    "            seq.add_module(\"conv_{0}\".format(i), conv)\n",
    "            \n",
    "            if \"batch_normalize\" in block:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                seq.add_module(\"batch_norm_{0}\".format(i), bn)\n",
    "\n",
    "            if activation == \"leaky\":\n",
    "                activn = nn.LeakyReLU(0.1, inplace = True)\n",
    "                seq.add_module(\"leaky_{0}\".format(i), activn)\n",
    "            \n",
    "        elif (block[\"type\"] == \"upsample\"):\n",
    "            upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\")\n",
    "            seq.add_module(\"upsample_{}\".format(i), upsample)\n",
    "        \n",
    "        elif (block[\"type\"] == 'route'):\n",
    "            # start and end is given in format (eg:-1 36 so we will find layer number from it.\n",
    "            # we will find layer number in negative format\n",
    "            # so that we can get the number of filters in that layer\n",
    "            block['layers'] = block['layers'].split(',')\n",
    "            block['layers'][0] = int(block['layers'][0])\n",
    "            start = block['layers'][0]\n",
    "            if len(block['layers']) == 1:               \n",
    "                filters = output_filters[i + start]\n",
    "                       \n",
    "            \n",
    "            elif len(block['layers']) > 1:\n",
    "                block['layers'][1] = int(block['layers'][1]) - i \n",
    "                end = block['layers'][1]\n",
    "                filters = output_filters[i + start] + output_filters[i + end]\n",
    "                  \n",
    "            \n",
    "            route = DummyLayer()\n",
    "            seq.add_module(\"route_{0}\".format(i),route)\n",
    "                \n",
    "      \n",
    "        elif block[\"type\"] == \"shortcut\":\n",
    "            from_ = int(block[\"from\"])\n",
    "            shortcut = DummyLayer()\n",
    "            seq.add_module(\"shortcut_{0}\".format(i),shortcut)\n",
    "            \n",
    "            \n",
    "        elif block[\"type\"] == \"yolo\":\n",
    "            mask = block[\"mask\"].split(\",\")\n",
    "            mask = [int(m) for m in mask]\n",
    "            anchors = block[\"anchors\"].split(\",\")\n",
    "            anchors = [(int(anchors[i]), int(anchors[i + 1])) for i in range(0, len(anchors), 2)]\n",
    "            anchors = [anchors[i] for i in mask]\n",
    "            block[\"anchors\"] = anchors\n",
    "            \n",
    "            detectorLayer = DetectionLayer(anchors)\n",
    "            seq.add_module(\"Detection_{0}\".format(i),detectorLayer)\n",
    "                \n",
    "        modulelist.append(seq)\n",
    "        output_filters.append(filters)  \n",
    "        channels = filters\n",
    "    \n",
    "    return darknet_details, modulelist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
